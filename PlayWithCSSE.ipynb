{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Playing with CSSE numbers\n",
    "## Get data here: [github](https://github.com/CSSEGISandData/COVID-19/tree/master/csse_covid_19_data/csse_covid_19_time_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import OrderedDict\n",
    "from dateutil.parser import parse\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "from scipy.signal import correlate\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do you want to re-download the data?\n",
    "This is update in the evenings, no need to re-download everytime you run it.\n",
    "Options are: 'no', or anything else"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "re_download = 'no'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make functions to import the data and massage it into a good format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ImportData(re_download):\n",
    "    if re_download.lower() != 'no':\n",
    "        print('downloading')\n",
    "        us_cases = pd.read_csv('https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_US.csv')\n",
    "        us_cases.to_csv('./data/time_series_covid19_confirmed_US.csv', encoding='utf-8', index=False)\n",
    "        global_cases = pd.read_csv('https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_global.csv')\n",
    "        global_cases.to_csv('./data/time_series_covid19_confirmed_global.csv', encoding='utf-8', index=False)\n",
    "        us_deaths = pd.read_csv('https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_deaths_US.csv')\n",
    "        us_deaths.to_csv('./data/time_series_covid19_deaths_US.csv', encoding='utf-8', index=False)\n",
    "        global_deaths = pd.read_csv('https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_deaths_global.csv')\n",
    "        global_deaths.to_csv('./data/time_series_covid19_deaths_global.csv', encoding='utf-8', index=False)\n",
    "        global_recovered = pd.read_csv('https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_recovered_global.csv')\n",
    "        global_recovered.to_csv('./data/time_series_covid19_recovered_global.csv', encoding='utf-8', index=False)\n",
    "    else:\n",
    "        print('not re-downloaded')\n",
    "        us_cases = pd.read_csv('./data/time_series_covid19_confirmed_US.csv')\n",
    "        global_cases = pd.read_csv('./data/time_series_covid19_confirmed_global.csv')\n",
    "        us_deaths = pd.read_csv('./data/time_series_covid19_deaths_US.csv')\n",
    "        global_deaths = pd.read_csv('./data/time_series_covid19_deaths_global.csv')\n",
    "        global_recovered = pd.read_csv('./data/time_series_covid19_recovered_global.csv')\n",
    "    return us_cases, global_cases, us_deaths, global_deaths, global_recovered\n",
    "\n",
    "def MakeNewDF(re_download='no'):\n",
    "    \"\"\"\n",
    "    Join the two DataFrames and add a few columns\n",
    "    \"\"\"\n",
    "    us_cases, global_cases, us_deaths, global_deaths, global_recovered = ImportData(re_download)\n",
    "    # For some reason cases is missing population\n",
    "    us_cases['Population'] = us_deaths['Population']\n",
    "\n",
    "    # Add a column for category\n",
    "    us_cases['category'] = 'cases'\n",
    "    us_deaths['category'] = 'deaths'\n",
    "\n",
    "    # Concat the DF's\n",
    "    big_df = us_cases.append(us_deaths, sort=False)\n",
    "    length_holder = len(big_df)\n",
    "\n",
    "    # Get State List\n",
    "    s_list = list(us_deaths.Province_State.unique())\n",
    "    # Get County List\n",
    "    cnty_list = list(us_deaths['Admin2'].unique())\n",
    "    del cnty_list[0]\n",
    "\n",
    "    # Make temp DF for state values\n",
    "    state_df = pd.DataFrame(columns=list(big_df.keys()))\n",
    "    for i, j in enumerate(s_list):\n",
    "        keep_dat = ['UID', 'iso2', 'iso3', 'code3', 'FIPS', 'Admin2', 'Province_State',\n",
    "                    'Country_Region', 'Lat', 'Long_', 'Combined_Key', 'category']\n",
    "        big_df.loc[length_holder + i] = us_cases.loc[us_cases['Province_State'] == j].sum()\n",
    "        big_df.loc[length_holder + i, keep_dat] = ['N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'all', j, 'US', 'N/A', 'N/A', 'N/A', 'cases']\n",
    "        big_df.loc[length_holder + len(s_list) + i] = us_deaths.loc[us_deaths['Province_State'] == j].sum()\n",
    "        big_df.loc[length_holder + len(s_list) + i, keep_dat] = ['N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'all', j, 'US', 'N/A', 'N/A', 'N/A', 'deaths']\n",
    "\n",
    "    date_list = [x for x in list(big_df.keys()) if x.startswith(('1', '2', '3', '4', '5', '6', '7'))]\n",
    "    date_pd = pd.to_datetime(date_list)\n",
    "    st_dict = OrderedDict(zip(s_list, s_list))\n",
    "    cnty_dict = OrderedDict(zip(cnty_list, cnty_list))\n",
    "    return big_df, date_pd, date_list, st_dict, cnty_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions for working with the arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DailyFromCumSum(arr):\n",
    "    daily_h = arr[1:] - arr[:-1]\n",
    "    daily = np.insert(daily_h, 0, 0, axis=0)\n",
    "    return daily\n",
    "\n",
    "def RollIt(np_arr, roll):\n",
    "    s = pd.Series(np_arr)\n",
    "    rolled = s.rolling(roll).mean()\n",
    "    return rolled\n",
    "\n",
    "def GetSeries(t_string, state, cnty, chop=False):\n",
    "    if 'State' in t_string:\n",
    "        cnty_var = 'all'\n",
    "    else:\n",
    "        cnty_var = cnty\n",
    "    if 'Cases' in t_string:\n",
    "        cat_var = 'cases'\n",
    "    else:\n",
    "        cat_var = 'deaths'\n",
    "    if 'Daily' in t_string:\n",
    "        return DailyFromCumSum(np.array(bdf[(bdf.Province_State == state)\n",
    "                                            & (bdf['Admin2'] == cnty_var)\n",
    "                                            & (bdf['category'] == cat_var)].loc[:, dl[:]])[0])\n",
    "    else:\n",
    "        return np.array(bdf[(bdf.Province_State == state)\n",
    "                            & (bdf['Admin2'] == cnty_var)\n",
    "                            & (bdf['category'] == cat_var)].loc[:, dl[:]])[0]\n",
    "\n",
    "def ChopSer(ar1, ar2):\n",
    "    chop = np.argmax(ar1>5)\n",
    "    return ar1[chop:], ar2[chop:]\n",
    "\n",
    "def PhaseShift(ar1, ar2):\n",
    "    ar1_chopped, ar2_chopped = ChopSer(ar1.copy(), ar2.copy())\n",
    "    chopped_length = len(ar1_chopped)\n",
    "    xcorr = correlate(ar1[-chopped_length:], ar2[-chopped_length:])\n",
    "    dt = np.linspace(-chopped_length, chopped_length, 2 * chopped_length - 1)\n",
    "#     fig2, ax = plt.subplots(figsize=(16, 10))\n",
    "#     fig.patch.set_facecolor(fig_facecolor)\n",
    "#     ax.set_facecolor(bg_color)\n",
    "#     ax.plot(dt, xcorr, color=color)\n",
    "#     plt.show()\n",
    "    recovered_time_shift = dt[xcorr.argmax()]\n",
    "    return recovered_time_shift"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the functions for getting our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not re-downloaded\n"
     ]
    }
   ],
   "source": [
    "bdf, dpd, dl, sl, cl = MakeNewDF(re_download)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set some parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_facecolor = 'xkcd:cloudy blue'\n",
    "bg_color = 'xkcd:really light blue'\n",
    "ts_color = 'tab:red'\n",
    "roll_color = 'xkcd:blue'\n",
    "roll_linewidth = 4.0\n",
    "x_rotation = 60\n",
    "tick_fontsize = 14\n",
    "label_fontsize = 16\n",
    "title_fontsize = 20\n",
    "legend_fontsize = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the interactive plotting widget\n",
    "NOTE: the dual plotting doesn't work anymore, I'll have to fix it later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5cb154d6dbb0471d84bb5a670a513494",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='which_plot', options={'State Cumulative Cases': 'State Cumulative â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def PlotIt(which_plot='Cumulative Cases', duo=None, state='Washington',\n",
    "           cnty='King', roll=10, show_roll=False, poly_trend=False):\n",
    "    # Set up the fig\n",
    "    fig, ax1 = plt.subplots(figsize=(16, 10))\n",
    "    fig.patch.set_facecolor(fig_facecolor)\n",
    "    ax1.set_facecolor(bg_color)\n",
    "    plt.xticks(fontsize=tick_fontsize, rotation=x_rotation)\n",
    "    plt.yticks(fontsize=tick_fontsize)\n",
    "\n",
    "    ax1.set_xlabel('Date', fontsize=label_fontsize)\n",
    "    \n",
    "    if which_plot.endswith('Cases'):\n",
    "        ax1.set_ylabel('Cases', fontsize=label_fontsize)\n",
    "    else:\n",
    "        ax1.set_ylabel('Deaths', fontsize=label_fontsize)\n",
    "\n",
    "    if which_plot.startswith('State'):\n",
    "        fig.suptitle(state + ' ' + which_plot, fontsize=title_fontsize)\n",
    "    else:\n",
    "        fig.suptitle(cnty + ' ' + which_plot, fontsize=title_fontsize)\n",
    "    series_one = GetSeries(which_plot, state, cnty)\n",
    "    ax1.plot(dpd, series_one, color=ts_color, label=which_plot + ' Count')\n",
    "    if show_roll:    \n",
    "        ma = RollIt(series_one, roll)\n",
    "        ax1.plot(dpd,\n",
    "                 ma, color=roll_color,\n",
    "                 linewidth=roll_linewidth,\n",
    "                 label=str(roll) + ' Day Rolling Avg')\n",
    "    ax1.legend(loc=2, fontsize=legend_fontsize, framealpha=.6)\n",
    "    ax1.tick_params(axis='y', labelcolor=ts_color)\n",
    "\n",
    "    if duo != None:\n",
    "        ax2 = ax1.twinx()\n",
    "        color = 'tab:blue'\n",
    "        ax2.tick_params(axis='y', labelcolor=color)\n",
    "        fig.suptitle(state + ' ' + which_plot + ' vs. ' + state + ' ' + duo, fontsize=label_fontsize)\n",
    "        series_two = GetSeries(duo, state, cnty)\n",
    "        ax2.plot(dpd, series_two, color=color, label=duo + ' Count')\n",
    "\n",
    "        # I need to be able to chop the series to the first case in order to do this properly\n",
    "        print(PhaseShift(series_one, series_two))\n",
    "\n",
    "        # TODO: Fix the cases vs. deaths problem here\n",
    "        if duo.endswith('Cases'):\n",
    "            ax2.set_ylabel('Cases', color=color, fontsize=label_fontsize)\n",
    "        else:\n",
    "            ax2.set_ylabel('Deaths', color=color, fontsize=label_fontsize)\n",
    "        # added these three lines\n",
    "#         lns = lns1+lns2+lns3\n",
    "#         labs = [l.get_label() for l in lns]\n",
    "#         ax1.legend(lns, labs, loc=0)\n",
    "        ax1.legend(loc=2, fontsize=legend_fontsize, framealpha=.6)\n",
    "\n",
    "    if poly_trend:\n",
    "        ar1_chopped, ar2_chopped = ChopSer(series_one.copy(), series_two.copy())\n",
    "        xnew = np.array(range(len(ar1_chopped)))\n",
    "        polynomial_coeff = np.polyfit(xnew, ar1_chopped, 2)\n",
    "        ynew = np.poly1d(polynomial_coeff)\n",
    "        ax1.plot(dpd[-len(ar1_chopped):], ynew(xnew), c='k')\n",
    "\n",
    "    # ax2.set_ylim(my_weight.min() - 5, my_weight.max() + 20)\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plt_one = {'State Cumulative Cases': 'State Cumulative Cases',\n",
    "           'State Cumulative Deaths': 'State Cumulative Deaths',\n",
    "           'State Daily Cases': 'State Daily Cases',\n",
    "           'State Daily Deaths': 'State Daily Deaths',\n",
    "           'County Cumalative Cases': 'County Cumulative Cases',\n",
    "           'County Cumulative Deaths': 'County Cumulative Deaths',\n",
    "           'County Daily Cases': 'County Daily Cases',\n",
    "           'County Daily Deaths': 'County Daily Deaths'}\n",
    "plt_two = plt_one.copy()\n",
    "plt_two['None'] = None\n",
    "interactive_plot = interactive(PlotIt,\n",
    "                               which_plot=plt_one,\n",
    "                               duo=plt_two,\n",
    "                               state=sl,\n",
    "                               cnty=cl,\n",
    "                               roll=widgets.IntSlider(min=4, max=20, step=1,\n",
    "                                                      description='Rolling Average:',\n",
    "                                                      continuous_update=False))\n",
    "output = interactive_plot.children[-1]\n",
    "interactive_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1/22/20',\n",
       " '1/23/20',\n",
       " '1/24/20',\n",
       " '1/25/20',\n",
       " '1/26/20',\n",
       " '1/27/20',\n",
       " '1/28/20',\n",
       " '1/29/20',\n",
       " '1/30/20',\n",
       " '1/31/20',\n",
       " '2/1/20',\n",
       " '2/2/20',\n",
       " '2/3/20',\n",
       " '2/4/20',\n",
       " '2/5/20',\n",
       " '2/6/20',\n",
       " '2/7/20',\n",
       " '2/8/20',\n",
       " '2/9/20',\n",
       " '2/10/20',\n",
       " '2/11/20',\n",
       " '2/12/20',\n",
       " '2/13/20',\n",
       " '2/14/20',\n",
       " '2/15/20',\n",
       " '2/16/20',\n",
       " '2/17/20',\n",
       " '2/18/20',\n",
       " '2/19/20',\n",
       " '2/20/20',\n",
       " '2/21/20',\n",
       " '2/22/20',\n",
       " '2/23/20',\n",
       " '2/24/20',\n",
       " '2/25/20',\n",
       " '2/26/20',\n",
       " '2/27/20',\n",
       " '2/28/20',\n",
       " '2/29/20',\n",
       " '3/1/20',\n",
       " '3/2/20',\n",
       " '3/3/20',\n",
       " '3/4/20',\n",
       " '3/5/20',\n",
       " '3/6/20',\n",
       " '3/7/20',\n",
       " '3/8/20',\n",
       " '3/9/20',\n",
       " '3/10/20',\n",
       " '3/11/20',\n",
       " '3/12/20',\n",
       " '3/13/20',\n",
       " '3/14/20',\n",
       " '3/15/20',\n",
       " '3/16/20',\n",
       " '3/17/20',\n",
       " '3/18/20',\n",
       " '3/19/20',\n",
       " '3/20/20',\n",
       " '3/21/20',\n",
       " '3/22/20',\n",
       " '3/23/20',\n",
       " '3/24/20',\n",
       " '3/25/20',\n",
       " '3/26/20',\n",
       " '3/27/20',\n",
       " '3/28/20',\n",
       " '3/29/20',\n",
       " '3/30/20',\n",
       " '3/31/20',\n",
       " '4/1/20',\n",
       " '4/2/20',\n",
       " '4/3/20',\n",
       " '4/4/20',\n",
       " '4/5/20',\n",
       " '4/6/20',\n",
       " '4/7/20',\n",
       " '4/8/20',\n",
       " '4/9/20',\n",
       " '4/10/20',\n",
       " '4/11/20',\n",
       " '4/12/20',\n",
       " '4/13/20',\n",
       " '4/14/20',\n",
       " '4/15/20',\n",
       " '4/16/20',\n",
       " '4/17/20',\n",
       " '4/18/20',\n",
       " '4/19/20',\n",
       " '4/20/20',\n",
       " '4/21/20',\n",
       " '4/22/20',\n",
       " '4/23/20',\n",
       " '4/24/20',\n",
       " '4/25/20',\n",
       " '4/26/20',\n",
       " '4/27/20',\n",
       " '4/28/20',\n",
       " '4/29/20',\n",
       " '4/30/20',\n",
       " '5/1/20',\n",
       " '5/2/20',\n",
       " '5/3/20',\n",
       " '5/4/20',\n",
       " '5/5/20',\n",
       " '5/6/20',\n",
       " '5/7/20',\n",
       " '5/8/20',\n",
       " '5/9/20',\n",
       " '5/10/20',\n",
       " '5/11/20',\n",
       " '5/12/20',\n",
       " '5/13/20',\n",
       " '5/14/20',\n",
       " '5/15/20',\n",
       " '5/16/20']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_dl = dl.copy()\n",
    "new_dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(6, 3))\n",
    "ax.set_title(\"What won't Meatloaf do for love?\")\n",
    "ax.pie([70, 20, 10], labels=['That', 'Also that, but in red', 'THAT!'], colors=['Blue', 'Red', 'Purple'])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "521.771px",
    "left": "1303.78px",
    "right": "20px",
    "top": "120px",
    "width": "342.882px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
